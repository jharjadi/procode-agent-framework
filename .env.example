# LLM Configuration - Set at least one API key to enable LLM-based intent classification
# The agent will auto-detect and use the first available provider in this order:
# 1. Ollama (Local, FREE) - Best for cost optimization
# 2. Anthropic (Claude 3 Haiku) - Cheap cloud option (12x cheaper than Sonnet)
# 3. Google (Gemini Flash-8B) - Cheap cloud option (2x cheaper than Flash)
# 4. OpenAI (GPT-4o-mini) - Already cost-optimized

# === COST-OPTIMIZED OPTIONS ===

# Option 1: Ollama (Local, FREE) - Recommended for development
# Install: brew install ollama
# Start: ollama serve
# Pull model: ollama pull llama3.2:3b
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2:3b

# Option 2: Anthropic Claude 3 Haiku (12x cheaper than Sonnet)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Option 3: Google Gemini Flash-8B (2x cheaper than Flash)
# GOOGLE_API_KEY=your-google-api-key-here
# GOOGLE_MODEL=gemini-1.5-flash-8b

# Option 4: OpenAI GPT-4o-mini (already cost-optimized)
# OPENAI_API_KEY=your-openai-api-key-here

# === MULTI-LLM STRATEGY SETTINGS ===

# Force specific provider for intent classification (optional)
# INTENT_LLM_PROVIDER=ollama  # or "anthropic", "google", "openai"
# LLM_PROVIDER=anthropic  # Fallback for backward compatibility

# Confidence threshold for deterministic classifier (0.0-1.0)
# Higher = fewer LLM calls = more cost savings
# CONFIDENCE_THRESHOLD=0.8  # Default: 80% confidence required

# Enable caching of intent classifications
# ENABLE_INTENT_CACHE=true

# Enable/disable LLM intent classification (default: true if any API key is set)
# USE_LLM_INTENT=true

# Tool Configuration
# Enable real GitHub API integration (default: false, uses mocked tools)
# USE_REAL_TOOLS=false
# GITHUB_TOKEN=your-github-token-here
# GITHUB_REPO=owner/repo

# Conversation Memory
# CONVERSATION_WINDOW_SIZE=10

# Agent URL (for console app)
# AGENT_URL=http://localhost:9998

# === DATABASE CONFIGURATION ===

# Database URL - Supports SQLite (dev) and PostgreSQL (prod)
# SQLite (default for development - no setup required)
# DATABASE_URL=sqlite:///data/procode.db
# SQLITE_DB_PATH=data/procode.db

# PostgreSQL (production)
# DATABASE_URL=postgresql://user:password@localhost:5432/procode_db
# Example with connection pooling:
# DATABASE_URL=postgresql://user:password@localhost:5432/procode_db?pool_size=5&max_overflow=10

# Database pool settings (PostgreSQL only)
# DB_POOL_SIZE=5
# DB_MAX_OVERFLOW=10

# Enable SQL query logging (useful for debugging)
# SQL_ECHO=false
